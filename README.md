# Resid√™ncia em TI - TJGO
## üß† Projeto Final ‚Äì Aplica√ß√£o de Aprendizagem de M√°quina em Problemas Reais

---

## üöÄ In√≠cio R√°pido - Ambiente Local

### Executar o Notebook Localmente

```bash
# 1. Entrar no diret√≥rio do projeto
cd ml-residencia-ti

# 2. Ativar o ambiente virtual
source venv/bin/activate

# 3. Iniciar Jupyter
jupyter notebook

# 4. Abrir NotebookFinal-3.ipynb na interface
```

**Ambiente configurado:**
- Python 3.11.14
- Todas as depend√™ncias instaladas (pandas, numpy, matplotlib, seaborn, scipy, gdown, jupyter)
- Arquivos: `requirements.txt` e `INSTRUCOES_AMBIENTE.md` (instru√ß√µes detalhadas)

---

## üéØ Objetivo Geral
Aplicar o ciclo completo de Aprendizagem de M√°quina, seguindo o processo **CRISP-DM (Cross-Industry Standard Process for Data Mining)**, para desenvolver uma solu√ß√£o baseada em dados que responda a um problema de neg√≥cio real.

---

## üß© Etapas do Projeto

### **1. Entendimento do Neg√≥cio (Business Understanding)**
- Identificar um problema real com relev√¢ncia pr√°tica (ex.: predi√ß√£o, classifica√ß√£o, recomenda√ß√£o).
- Descrever o contexto e o impacto esperado da solu√ß√£o.
- Formular as perguntas de neg√≥cio e definir os objetivos do projeto.
- Exemplo: *Como prever o cancelamento de clientes a partir de dados de uso?*

**Entreg√°vel:**  
üìÑ Documento (1 p√°gina) descrevendo o problema, o objetivo do projeto e poss√≠veis m√©tricas de sucesso (KPIs).

---

### **2. Entendimento dos Dados (Data Understanding)**
- Selecionar e descrever o dataset (fonte, volume, vari√°veis, limita√ß√µes).
- Analisar a qualidade dos dados, presen√ßa de *outliers*, e distribui√ß√£o das vari√°veis.
- Visualizar padr√µes iniciais e poss√≠veis rela√ß√µes entre vari√°veis (correla√ß√£o, dispers√£o, histogramas).

**Entreg√°vel:**  
üìì Notebook com an√°lise explorat√≥ria (*EDA*) e breve resumo interpretativo dos achados.

---

### **3. Prepara√ß√£o dos Dados (Data Preparation)**
- Realizar limpeza, codifica√ß√£o de vari√°veis, normaliza√ß√£o e engenharia de atributos.
- Criar pipeline de pr√©-processamento (ex.: `Pipeline` do Scikit-learn).
- Documentar as decis√µes tomadas e justificar as transforma√ß√µes realizadas.

**Entreg√°vel:**  
üìì Notebook com o pipeline completo de prepara√ß√£o de dados e dataset pronto para modelagem.

---

### **4. Modelagem (Modeling)**

Cada grupo dever√° **escolher um tipo de aprendizado** e aplicar **duas ou mais abordagens complementares** do mesmo tipo, comparando desempenho, robustez e limita√ß√µes.

---

#### üß© **Op√ß√£o 1 ‚Äì Aprendizado Supervisionado**
**Objetivo:** Prever uma vari√°vel alvo (regress√£o ou classifica√ß√£o).

**Exemplos de algoritmos:**
- Regress√£o Linear e Log√≠stica  
- Decision Tree, Random Forest, SVM  
- XGBoost, LightGBM  

**Frameworks recomendados:**
- [Scikit-learn](https://scikit-learn.org/stable/)  
- [XGBoost](https://xgboost.readthedocs.io/)  
- [LightGBM](https://lightgbm.readthedocs.io/)

**M√©tricas:**
- Regress√£o: MAE, RMSE, R¬≤  
- Classifica√ß√£o: Accuracy, Precision, Recall, F1, ROC-AUC  

üìì *Sugest√£o:* comparar um modelo linear e um n√£o linear sobre o mesmo conjunto de dados.

---

#### üß© **Op√ß√£o 2 ‚Äì Aprendizado N√£o Supervisionado**
**Objetivo:** Identificar padr√µes ou agrupar dados n√£o rotulados.

**Exemplos de algoritmos:**
- K-Means, DBSCAN, Hierarchical Clustering  
- PCA, t-SNE (redu√ß√£o de dimensionalidade)

**Frameworks recomendados:**
- [Scikit-learn](https://scikit-learn.org/stable/)  
- [Yellowbrick](https://www.scikit-yb.org/en/latest/) (visualiza√ß√£o de clusters)

**M√©tricas:**
- Silhouette, Calinski-Harabasz, Davies-Bouldin  

üìì *Sugest√£o:* comparar dois algoritmos de clusteriza√ß√£o sobre o mesmo dataset.

---

#### üß© **Op√ß√£o 3 ‚Äì Aprendizado Semi-Supervisionado ou Auto-Supervisionado**
**Objetivo:** Usar dados parcialmente rotulados ou aprender representa√ß√µes sem r√≥tulos humanos.

**Exemplos de algoritmos:**
- Label Propagation, Self-Training, Pseudo-Labeling  
- Autoencoder (para aprendizado de representa√ß√µes)  

**Frameworks recomendados:**
- [Scikit-learn (semi-supervised)](https://scikit-learn.org/stable/modules/label_propagation.html)  
- [TensorFlow/Keras](https://keras.io/examples/)  
- [PyTorch](https://pytorch.org/tutorials/)

üìì *Sugest√£o:* treinar um modelo supervisionado convencional e outro pr√©-treinado com autoencoder para compara√ß√£o.

---

#### üß© **Op√ß√£o 4 ‚Äì Aprendizado por Refor√ßo**
**Objetivo:** Aprender a tomar decis√µes por tentativa e erro, maximizando uma recompensa acumulada.

**Exemplos de algoritmos:**
- Q-Learning, SARSA (tabulares)  
- Deep Q-Network (DQN)  

**Frameworks cl√°ssicos recomendados:**
- [OpenAI Gymnasium](https://gymnasium.farama.org/) (ambientes de simula√ß√£o)  
- [Stable-Baselines3](https://stable-baselines3.readthedocs.io/) (implementa√ß√µes simples de RL)  
- [Gymnasium Classic Control environments](https://gymnasium.farama.org/environments/classic_control/) (ex.: CartPole, MountainCar, FrozenLake)

**M√©tricas:**
- Recompensa m√©dia por epis√≥dio  
- Estabilidade da pol√≠tica aprendida  
- Taxa de sucesso  

üìì *Sugest√£o:* comparar Q-Learning (tabular) com DQN (rede neural simples) em um ambiente b√°sico como CartPole.

---

#### üß© **Op√ß√£o 5 ‚Äì Sistemas de Recomenda√ß√£o**
**Objetivo:** Desenvolver modelos capazes de sugerir itens (produtos, filmes, cursos, etc.) a usu√°rios com base em prefer√™ncias e comportamento hist√≥rico.

**Abordagens principais:**
- **Baseadas em Conte√∫do:** usam similaridade entre itens ou descri√ß√µes.  
- **Colaborativas:** usam padr√µes de intera√ß√£o entre usu√°rios e itens.  
- **H√≠bridas:** combinam m√∫ltiplas fontes de informa√ß√£o.

**Exemplos de algoritmos:**
- Filtragem Colaborativa Usu√°rio-Usu√°rio e Item-Item  
- Matrix Factorization (SVD, ALS)  
- Regress√£o para pontua√ß√£o de prefer√™ncia  
- Recomenda√ß√£o via embeddings (Word2Vec, Autoencoder)  

**Frameworks cl√°ssicos recomendados:**
- [Scikit-surprise](http://surpriselib.com/) (modelos colaborativos cl√°ssicos)  
- [Implicit](https://github.com/benfred/implicit) (ALS e recomenda√ß√µes impl√≠citas)  
- [TensorFlow Recommenders](https://www.tensorflow.org/recommenders)  
- [LightFM](https://making.lyst.com/lightfm/docs/home.html) (modelo h√≠brido simples e eficiente)

**M√©tricas:**
- Precision@K, Recall@K  
- Mean Average Precision (MAP)  
- Normalized Discounted Cumulative Gain (nDCG)  

üìì *Sugest√£o:* implementar e comparar duas abordagens distintas ‚Äî por exemplo, um modelo de filtragem colaborativa e outro baseado em conte√∫do ‚Äî e avaliar o desempenho com m√©tricas de ranking.

---

**Entreg√°vel (para todas as op√ß√µes):**  
üìì Notebook com experimentos e compara√ß√£o cr√≠tica entre as abordagens do mesmo tipo de aprendizado, destacando vantagens, limita√ß√µes e aplicabilidade pr√°tica.

---

### **5. Avalia√ß√£o (Evaluation)**
- Avaliar os modelos com m√©tricas adequadas:
  - **Regress√£o:** MAE, RMSE, R¬≤  
  - **Classifica√ß√£o:** Precision, Recall, F1-score, ROC-AUC  
  - **Clusteriza√ß√£o:** Silhouette, Calinski-Harabasz  
- Comparar o desempenho entre modelos e discutir a adequa√ß√£o de cada um ao problema de neg√≥cio.
- Relacionar as m√©tricas de ML com indicadores reais (KPIs).

**Entreg√°vel:**  
üìÑ Relat√≥rio t√©cnico (2‚Äì3 p√°ginas) contendo as m√©tricas, gr√°ficos e an√°lise cr√≠tica dos resultados.

---

### **6. Implanta√ß√£o e Comunica√ß√£o (Deployment)**
- Preparar uma **apresenta√ß√£o de 5 a 8 minutos** contendo:
  - Problema ‚Üí Solu√ß√£o proposta ‚Üí Resultados ‚Üí Conclus√µes.
- Entregar notebook final e slides com visualiza√ß√µes e conclus√µes.
- (Opcional) Expor o modelo via API simples (Flask/FastAPI) ou dashboard (Streamlit).

**Entreg√°vel:**  
üé§ Apresenta√ß√£o final + link para o reposit√≥rio (GitHub, Google Colab, ou Kaggle Notebook).

---

## üìä Crit√©rios de Avalia√ß√£o

| Crit√©rio | Peso | Descri√ß√£o |
|-----------|------|-----------|
| **Entendimento do neg√≥cio** | 15% | Clareza e relev√¢ncia da formula√ß√£o do problema. |
| **Entendimento e an√°lise dos dados** | 15% | Qualidade da an√°lise explorat√≥ria e insights obtidos. |
| **Prepara√ß√£o dos dados** | 20% | Corre√ß√£o e justificativa das transforma√ß√µes. |
| **Modelagem** | 30% | Aplica√ß√£o e compara√ß√£o de algoritmos. |
| **Avalia√ß√£o e interpreta√ß√£o** | 20% | Uso correto de m√©tricas e an√°lise cr√≠tica. |

---

## üíº Ideias de Projetos para o TJ

A seguir est√£o sugest√µes de temas e linhas de investiga√ß√£o que os grupos podem explorar no projeto final, considerando o contexto do Tribunal de Justi√ßa.

---

### üß© **1. Aprendizado Supervisionado**
Foco em **previs√£o e classifica√ß√£o** com dados rotulados.

- Previs√£o do **tempo m√©dio de tramita√ß√£o** de processos com base em tipo, assunto e hist√≥rico.  
- Classifica√ß√£o autom√°tica de **tipos de peti√ß√µes** (inicial, recurso, manifesta√ß√£o, despacho).  
- Identifica√ß√£o de **processos com alto risco de atraso**.  
- Predi√ß√£o de **reforma de senten√ßa** em inst√¢ncias superiores.  
- Classifica√ß√£o de **decis√µes judiciais** (deferimento, indeferimento, arquivamento).

---

### üß© **2. Aprendizado N√£o Supervisionado**
Foco em **descoberta de padr√µes e agrupamentos** sem r√≥tulos.

- Agrupar **decis√µes ou ac√≥rd√£os** por similaridade de conte√∫do jur√≠dico.  
- Clusterizar **processos semelhantes** em estrutura ou tramita√ß√£o.  
- Detectar **anormalidades** em prazos ou movimenta√ß√µes processuais.  
- Descobrir **perfis de produtividade** de varas, ju√≠zes ou servidores.  
- Identificar **padr√µes incomuns** em dados administrativos ou financeiros.

---

### üß© **3. Aprendizado Semi-Supervisionado e Auto-Supervisionado**
Foco em **aproveitar grandes volumes de dados com poucos r√≥tulos**.

- Classificar **tipos de decis√µes** com apenas um pequeno conjunto de exemplos rotulados.  
- Criar **embeddings de textos jur√≠dicos** com autoencoders para melhorar outras tarefas de ML.  
- Detectar **senten√ßas at√≠picas** ou **decis√µes fora do padr√£o** em grandes bases de ac√≥rd√£os.  
- Usar *pseudo-labeling* para expandir conjuntos de dados de peti√ß√µes parcialmente rotuladas.

---

### üß© **4. Aprendizado por Refor√ßo**
Foco em **otimizar pol√≠ticas e fluxos de decis√£o sequencial**.

- Simular **distribui√ß√£o de processos entre servidores ou varas**, buscando equilibrar carga de trabalho.  
- Aprender pol√≠ticas de **prioriza√ß√£o de tarefas** (por tipo de processo, prazos ou impacto).  
- Otimizar o **uso de recursos computacionais** em filas de processamento automatizado.  
- Modelar um agente que aprenda a **minimizar atrasos** em tr√¢mites administrativos ou judiciais.

*(Esses projetos podem usar simula√ß√µes simples com `Gymnasium` e `Stable-Baselines3`, representando o fluxo de processos como um ambiente interativo.)*

---

### üß© **5. Sistemas de Recomenda√ß√£o**
Foco em **apoio √† decis√£o e recupera√ß√£o inteligente de informa√ß√£o jur√≠dica**.

- Recomenda√ß√£o de **jurisprud√™ncias semelhantes** para casos em an√°lise.  
- Sugest√£o de **artigos de lei ou dispositivos legais** relevantes para um texto de peti√ß√£o.  
- Recomenda√ß√£o de **modelos de documentos** (despachos, decis√µes) com base em casos anteriores.  
- Sugest√£o de **tarefas priorit√°rias** ou **distribui√ß√£o otimizada de processos** a servidores.  
- Recomenda√ß√£o de **cursos e materiais de capacita√ß√£o** a magistrados e servidores conforme perfil e hist√≥rico de atua√ß√£o.

*(Esses projetos podem usar bibliotecas como `Scikit-surprise`, `LightFM`, `Implicit` ou `TensorFlow Recommenders`.)*

---

## üß† Ferramentas Recomendadas
- **Linguagem:** Python  
- **Bibliotecas:** Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, TensorFlow/Keras  
- **Ambiente:** Google Colab ou Jupyter Notebook  
- **Versionamento:** GitHub  
- **Fontes de Dados:** TJGO, Kaggle, Open Data Brasil, etc.

---

## üìÖ Entregas Sugeridas

| Etapa | Entreg√°vel | Prazo sugerido |
|-------|-------------|----------------|
| Entendimento do neg√≥cio e dos dados | Documento + EDA | Semana 6 |
| Prepara√ß√£o e modelagem inicial | Pipeline + Experimentos iniciais | Semana 7 |
| Avalia√ß√£o e refinamento | Relat√≥rio t√©cnico | Semana 8 |
| Apresenta√ß√£o final | Slides + Reposit√≥rio | Semana 9 |

---

## üìò Refer√™ncias
- LESKOVEC, J.; RAJARAMAN, A.; ULLMAN, J. *Mining of Massive Datasets*. Cambridge University Press, 2020.  
- GERON, A. *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow*. O‚ÄôReilly, 2022.  
- ZHOU, Z.-H. *A Brief Introduction to Weakly Supervised Learning*. *National Science Review*, 2021.  
- VAN ENGENLEN, T.; HOOS, H. *A Survey on Semi-Supervised Learning*. *Machine Learning Journal*, Springer, 2020.  
- RICCI, F.; ROKACH, L.; SHAPIRA, B. *Recommender Systems Handbook*. Springer, 2022.

---

‚ú≥Ô∏è **Entrega Final:**  
Os alunos dever√£o submeter:
1. **Notebook completo** (com todas as etapas do CRISP-DM).  
2. **Relat√≥rio t√©cnico (PDF)**.  
3. **Apresenta√ß√£o (slides)**.  
4. **Link para o reposit√≥rio** contendo c√≥digo e documenta√ß√£o.
